{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "from pyro.distributions import Normal\n",
    "from pyro.infer.autoguide.guides import AutoDelta\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "import torch.utils as utils\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0+cu92\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(lambda x: x.view(-1))])\n",
    "\n",
    "dataset_train = datasets.MNIST(\n",
    "    '~/mnist', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform)\n",
    "dataset_valid = datasets.MNIST(\n",
    "    '~/mnist', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform)\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "dataloader_train = utils.data.DataLoader(dataset_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)\n",
    "dataloader_valid = utils.data.DataLoader(dataset_valid,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, x_dim, z_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        # 中間層のユニット数\n",
    "        num = 200\n",
    "        self.fc3 = nn.Linear(z_dim, num)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.fc4 = nn.Linear(num, x_dim)\n",
    "    \n",
    "    def forward(self, z):\n",
    "      y = F.relu(self.fc3(z))\n",
    "      y = self.drop1(y)\n",
    "      y = torch.sigmoid(self.fc4(y))\n",
    "      return y\n",
    "\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, x_dim, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(x_dim, 200)\n",
    "        self.bn1 = nn.BatchNorm1d(200)\n",
    "        self.fc2_mean = nn.Linear(200, z_dim)\n",
    "        self.fc2_var = nn.Linear(200, z_dim)\n",
    "    \n",
    "    def forward(self, x, x_dim):\n",
    "        x = x.view(-1, x_dim)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bn1(x)\n",
    "        mean = self.fc2_mean(x)\n",
    "        log_var = self.fc2_var(x)\n",
    "        return mean, log_var\n",
    "        \n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.x_dim = x_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.sigma_w = 1.0\n",
    "        \n",
    "        self.decoder = Decoder(x_dim, z_dim)\n",
    "        # Decoderをベイズモデル化（Wに事前分布）\n",
    "        prior_w1 = Normal(torch.zeros(size=(z_dim, 200)), self.sigma_w * torch.ones(size=(z_dim, 200)))\n",
    "        prior_w2 = Normal(torch.zeros(size=(200, x_dim)), self.sigma_w * torch.ones(size=(200, x_dim)))\n",
    "        priors = {'fc1.weight': prior_w1, 'fc2.weight': prior_w2}\n",
    "        lifted_decoder = pyro.random_module(\"w_module\", self.decoder, priors)\n",
    "        self.encoder = Encoder(x_dim, z_dim)\n",
    "        \n",
    "\n",
    "\n",
    "    def sample_z(self, mean, log_var):\n",
    "        # torch.randn: N(0, 1)からサンプル  \n",
    "        epsilon = torch.randn(mean.shape, device=\"cuda\")\n",
    "        return mean + epsilon * torch.exp(0.5*log_var)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, self.x_dim)\n",
    "        mean, log_var = self.encoder(x, self.x_dim)\n",
    "        z = self.sample_z(mean, log_var)\n",
    "        y = self.decoder(z)\n",
    "        return z, y\n",
    "\n",
    "    def loss_sigmoid(self, x):\n",
    "        # 一つ目の引数に-1を指定することで２つ目の引数で指定した値にサイズ数を自動的に調整\n",
    "        x = x.view(-1, self.x_dim)\n",
    "        mean, log_var = self.encoder(x, self.x_dim)\n",
    "        delta = 1e-8\n",
    "        KL_z = 0.5 * torch.sum(1 + log_var - mean**2 - torch.exp(log_var))\n",
    "#         KL_w\n",
    "        z = self.sample_z(mean, log_var)\n",
    "        y = self.decoder(z)\n",
    "        reconstruction = torch.mean(x * torch.log(y + delta) + (1 - x) * torch.log(1 - y + delta))\n",
    "        lower_bound = [KL_z, reconstruction]\n",
    "        return -sum(lower_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0 loss: 0.22262634336948395 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = VAE(x_dim=28*28, z_dim=10).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model.train()\n",
    "\n",
    "num_epochs = 1\n",
    "loss_list = []\n",
    "for i in range(num_epochs):\n",
    "  losses = []\n",
    "  for x, t in dataloader_train:\n",
    "      x = x.to(device)\n",
    "      model.zero_grad()\n",
    "      z, y = model(x)\n",
    "      loss = model.loss_sigmoid(x)/batch_size\n",
    "     # 誤差逆伝播\n",
    "      loss.backward()\n",
    "     # パラメータ更新\n",
    "      optimizer.step()\n",
    "      losses.append(loss.cpu().detach().numpy())\n",
    "  loss_list.append(np.average(losses))\n",
    "  print(\"EPOCH: {} loss: {}\".format(i, np.average(losses)), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(num_epochs), loss_list, 'r-', label='train_loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "model.eval()\n",
    "zs = []\n",
    "for x, t in dataloader_valid:\n",
    "    for i, im in enumerate(x.view(-1, 28, 28).detach().numpy()[:10]):\n",
    "      ax = fig.add_subplot(3, 10, i+1, xticks=[], yticks=[])\n",
    "      ax.imshow(im, 'gray')\n",
    "\n",
    "    x = x.to(device)\n",
    "    z, y = model(x)\n",
    "    zs.append(z)\n",
    "    y = y.view(-1, 28, 28)\n",
    "    for i, im in enumerate(y.cpu().detach().numpy()[:10]):\n",
    "      ax = fig.add_subplot(3, 10, i+11, xticks=[], yticks=[])\n",
    "      ax.imshow(im, 'gray')\n",
    "    \n",
    "    z1to0 = torch.cat([z[1, :] * (i * 0.1) + z[0, :] * ((10 - i) * 0.1) for i in range(10)]).reshape(10, 10)\n",
    "    y2 = model.decoder(z1to0).view(-1, 28, 28)\n",
    "    for i, im in enumerate(y2.cpu().detach().numpy()[:20]):\n",
    "      ax = fig.add_subplot(3, 10, i+21, xticks=[], yticks=[])\n",
    "      ax.imshow(im, 'gray')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from random import random\n",
    "\n",
    "colors = [\"red\", \"green\", \"blue\", \"orange\", \"purple\", \"brown\", \"fuchsia\", \"grey\", \"olive\", \"lightblue\"]\n",
    "def visualize_zs(zs, labels):\n",
    "  plt.figure(figsize=(10,10))\n",
    "  points = TSNE(n_components=2, random_state=0).fit_transform(zs)\n",
    "  for p, l in zip(points, labels):\n",
    "    plt.scatter(p[0], p[1], marker=\"${}$\".format(l), c=colors[l])\n",
    "  plt.show()\n",
    "\n",
    "model.eval()\n",
    "zs = []\n",
    "for x, t in dataloader_valid:\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    # generate from x\n",
    "    y, z = model(x)\n",
    "    z = z.cpu()\n",
    "    t = t.cpu()\n",
    "    visualize_zs(z.detach().numpy(), t.cpu().detach().numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
